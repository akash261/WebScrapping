{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "3ygeMW3QnlQy",
    "outputId": "5f1561b0-f33e-494b-b82a-d025be219e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:4 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,284 kB]\n",
      "Hit:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Fetched 1,536 kB in 2s (802 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "chromium-chromedriver is already the newest version (76.0.3809.100-0ubuntu0.18.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
      "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
     ]
    }
   ],
   "source": [
    "#install chromium, its driver, and selenium:\n",
    "!pip install selenium\n",
    "!apt-get update # to update ubuntu to correctly run apt install\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_LiPSPbsFLU"
   },
   "outputs": [],
   "source": [
    "#set options to be headless\n",
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "-oeRn2mytbIq",
    "outputId": "9f3aba49-74cd-4a83-b9e5-436f1e626cdb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: use options instead of chrome_options\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "wd.get(\"https://www.prokabaddi.com/schedule-fixtures-results\")\n",
    "#print(wd.page_source) # results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BqFn3HJoiho"
   },
   "source": [
    "## Webscraping for Pro Kabbaddi Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fJCAXADVo19B",
    "outputId": "287aedc1-db3c-432b-a694-204ef98961f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a csv for the match details and create a header\n",
    "out_filename = \"Match_Details.csv\"\n",
    "headers = \"match_number,season,date,time,status,team_name1,team_name2,team1_score,team2_score,venue,result_text \\n\"\n",
    "\n",
    "# opens file, and writes headers\n",
    "f = open(out_filename, \"w\")\n",
    "f.write(headers)\n",
    "\n",
    "# create a csv for the match details and create a header\n",
    "teamstats_filename = \"Team_Stats.csv\"\n",
    "stat_header = \"Team_Name,Season,Matches_Played,Wins,Draws,Losses, Finishing_Position,Highest Score,Biggest_Win_Margin,Total Raids,Succesful_Raids,\" +  \\\n",
    "              \"Unsuccessful_raids,Empty_Raids, Success_Raid_%, No_Super_Raids, Raid_Touch_Points,\" + \\\n",
    "              \"Raid_Bonus_Points,Total_Raid_Points,Total_Tackles,Successfull_Tackles,\" + \\\n",
    "               \"Unsuccessful_Tackles,Successful_Tackle_%,No_Super_Tackles,\" + \\\n",
    "               \"Allouts_Inflicted,Total_Allout_Points,Total_Defence_Points\\n\"\n",
    "# opens file, and writes headers\n",
    "f1 = open(teamstats_filename, \"w\")\n",
    "f1.write(stat_header)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8Cx1yOUo4A2"
   },
   "outputs": [],
   "source": [
    "for k in range(1,7):\n",
    "  fetch_season = \"Season \" + str(k)\n",
    "  #Select the season by finding the select box option.\n",
    "  get_div = Select(wd.find_element_by_class_name('si-selectBox.si-season-change'))\n",
    "  #get_div.get_attribute(\"class\")\n",
    "  #get_div.select_by_index(5)\n",
    "  get_div.select_by_visible_text(fetch_season)\n",
    "  time.sleep(2)\n",
    "  #print(wd.page_source) # results\n",
    "\n",
    "  # Find the current season which is selected earlier. Also verify if the page is \n",
    "  # refreshing and active season matches with the selection we selected earlier \n",
    "  # from earlier code.\n",
    "  soup = BeautifulSoup(wd.page_source, 'html') \n",
    "  selectseasonwrapper = soup.find(\"li\", {\"class\": \"si-season-wrapper\"})\n",
    "  Match_Season = selectseasonwrapper.div.select(\"span\")[0].text\n",
    "  container = soup.find(\"div\", {\"class\": \"mwl-partial-container\"})\n",
    "  container\n",
    "  container.get_text()\n",
    "  #Now parse through each match and get the match attributes.\n",
    "  single_match_list = container.find_all(\"div\", {\"class\": \"si-fix-box si-single-match matCompleted \"})\n",
    "  for single_match_container in single_match_list:\n",
    "    MatchNumber = single_match_container.get(\"data-gamecode\")\n",
    "\n",
    "    DateContainer = single_match_container.find(\"div\", {\"class\": \"si-fix-box-top-flexBox si-flexBox\"})\n",
    "    MatchDate = DateContainer.div.select(\"span\")[0].text.replace(\",\", \"\")\n",
    "    MatchDate\n",
    "    MatchTime = DateContainer.select(\"div\")[1].text.strip()\n",
    "    MatchStatus = DateContainer.select(\"div\")[2].span.text\n",
    "\n",
    "    #find the match teams, location, final score\n",
    "    matchdetails_container = single_match_container.find_all(\"div\", {\"class\": \"si-fullName\"})\n",
    "    teams = []\n",
    "    for teamname in matchdetails_container:\n",
    "      teams.append(teamname.get_text().replace(\"\\n\", \"\"))\n",
    "    Match_Team1 = teams[0]\n",
    "    Match_Team2 = teams[1]\n",
    "\n",
    "    scoredetails_container = single_match_container.find(\"div\", {\"class\": \"matScore\"})\n",
    "    Match_Scores = scoredetails_container.select(\"span\")[0].text.split(' - ')\n",
    "    Match_Team1_Score = Match_Scores[0].strip()\n",
    "    Match_Team2_Score = Match_Scores[1].strip() \n",
    "\n",
    "    venue_container = single_match_container.find(\"div\", {\"class\": \"mat-venue\"})\n",
    "    Match_Venue = venue_container.select(\"span\")[0].text.strip()\n",
    "    Match_Venue = Match_Venue.replace(\",\", \"\")\n",
    "\n",
    "    result_container = single_match_container.find(\"div\", {\"class\": \"mat-resultStatus\"})\n",
    "    Match_Result = result_container.select(\"span\")[0].text.strip()\n",
    "    Match_Result\n",
    "\n",
    "    tempstr = MatchNumber + \",\" + Match_Season + \",\" + MatchDate + \",\" + MatchTime + \",\" + MatchStatus  \\\n",
    "              + \",\" + Match_Team1 + \",\" + Match_Team2 + \",\" + Match_Team1_Score    \\\n",
    "              + \",\" + Match_Team2_Score + \",\" + Match_Venue + \",\" + Match_Result + \"\\n\"\n",
    "    f.write(tempstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DhVRh3Nzn1Y"
   },
   "outputs": [],
   "source": [
    "f.close() #close the file\n",
    "wd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiWfcUQ-ssaC"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Match_Details.csv\") \n",
    "df.head()\n",
    "\n",
    "from google.colab import files\n",
    "files.download('Match_Details.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXhMLpHGu83q"
   },
   "source": [
    "### Scape the data from the teams pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "hCwJYXW93VJt",
    "outputId": "6371601b-ab62-4ba6-a765-cda9709326f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: use options instead of chrome_options\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "wd.get(\"https://www.prokabaddi.com/stats\")\n",
    "#print(wd.page_source) # results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ_g2m6L4Bms"
   },
   "outputs": [],
   "source": [
    "#loop through to get the links for all the individual team stats.\n",
    "soup = BeautifulSoup(wd.page_source, 'html') \n",
    "teamlink_container = soup.find(\"li\", {\"class\": \"submenu teams\"})\n",
    "teamlink_container \n",
    "link_atags = teamlink_container.div.select(\"a\")\n",
    "link_list = []\n",
    "for i in range(0,12):\n",
    "  link_list.append(\"https://www.prokabaddi.com\" + link_atags[i].get(\"href\"))\n",
    "wd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "OUdfOSFdED1L",
    "outputId": "2b0ab107-9bf6-44bc-d4aa-d165e21bf1ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Now loop through each of the team profile links to get team stats\n",
    "for i in range(len(link_list)):\n",
    "  wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "  wd.get(link_list[i])\n",
    "  time.sleep(3)\n",
    "  f1_team_name = link_list[i][link_list[i].rfind(\"/\") + 1:link_list[i].find(\"-profile\")].replace(\"-\",\" \")\n",
    "  #print(wd.page_source) # results\n",
    "  stats_soup = BeautifulSoup(wd.page_source, 'html')\n",
    "  stats_container = stats_soup.find(\"div\", {\"class\": \"si-stats-container\"})\n",
    "  stats_container_right = stats_container.find(\"div\", {\"class\": \"si-section-data si-right\"})\n",
    "  stats_container_right_table = stats_container_right.find_all(\"div\", {\"class\": \"si-tbl-wraper\"})\n",
    "  season_header = []\n",
    "  final_data = []\n",
    "  no_of_seasons = 0\n",
    "  season_counter = 0\n",
    "  for table_wrapper in stats_container_right_table:\n",
    "      data_blocks_wrapper = []\n",
    "      table_data_containers = table_wrapper.find_all(\"div\", {\"class\": \"si-tbl-data\"})\n",
    "      for table_data in table_data_containers:\n",
    "        data_blocks = table_data.find_all(\"div\", {\"class\": \"si-data-block\"})\n",
    "        data_points = []\n",
    "        for data_blocks in data_blocks:\n",
    "          if np.shape(table_wrapper.get(\"class\"))[0] == 2:     #identify header block\n",
    "            no_of_seasons += 1\n",
    "            season_header.append(data_blocks.get_text().strip())\n",
    "          else:\n",
    "            tempstr = data_blocks.get_text().strip()\n",
    "            if (tempstr.find('\\n') != -1):\n",
    "              tempstr = tempstr[0:tempstr.find('\\n')]\n",
    "            data_points.append(tempstr)\n",
    "            #print(data_blocks.get_text())\n",
    "        data_blocks_wrapper.append(data_points) \n",
    "      final_data.append(data_blocks_wrapper)\n",
    "      #print(data_blocks_wrapper)     \n",
    "  wd.close()\n",
    "  for r in range(np.shape(final_data)[1]):     #Season level\n",
    "    f1_writestr = f1_team_name + \",\" + season_header[r]\n",
    "    for p in range(1, np.shape(final_data)[0]):  #Wrapper level  \n",
    "      f1_writestr = f1_writestr + \",\" + \",\".join(final_data[p][r])\n",
    "    #print(f1_writestr)\n",
    "    f1.write(f1_writestr + \" \\n\")\n",
    "  #break\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCO3YTfPsZa6"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('Team_Stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LB1Ol9Ba0UAm"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!cp Match_Details.csv /content/gdrive/My\\ Drive/\n",
    "!cp Team_Stats.csv /content/gdrive/My\\ Drive/\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ProKabaddiScraper2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
